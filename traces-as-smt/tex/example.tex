% ---------------------------------------------------------------------
% Save boxes for the various figures in the example section
% ---------------------------------------------------------------------
\newsavebox{\boxTZero}
\begin{lrbox}{\boxTZero}
\begin{minipage}[t]{0.65\linewidth}
\begin{alltt}
00 initialize(NODE_0,&v,&s);
01 e0 = create_endpoint(PORT_0,&s);

02 msg_recv_i(e0,A,sizeof(A),&h1,&s);
03 wait(&h1,&size,&s,MCAPI_INF);
04 a = atoi(A);

05 msg_recv_i(e0,B,sizeof(B),&h2,&s);
06 wait(&h2,&size,&s,MCAPI_INF);
07 b = atoi(B);

08 if(b > 0);
09  assert(a == 4);

10 finalize(&s);
\end{alltt}
\end{minipage}
\end{lrbox}

\newsavebox{\boxATZero}
\begin{lrbox}{\boxATZero}
\begin{minipage}[t]{0.65\linewidth}
\begin{alltt}
08 0_0         (0_0 (rcvi rcvA 0 a))
09 (0_1 (0 1)) (0_1 (wait rcvA))

10 0_2         (0_2 (rcvi rcvB 0 b))
11 (0_3 (0 2)) (0_3 (wait rcvB))

12 0_4         (0_4 (assume (> b 0)))
13 0_5         (0_5 (assert (= a 4)))
\end{alltt}
\end{minipage}
\end{lrbox}

\newsavebox{\boxTOne}
\begin{lrbox}{\boxTOne}
\begin{minipage}[t]{0.65\linewidth}
\begin{alltt}
00 initialize(NODE_1,&v,&s);
01 e1 = create_endpoint(PORT_1,&s);
02 e0 = get_endpoint(NODE_0,PORT_0,&s);

03 msg_recv_i(e1,C,sizeof(C),&h3,&s);
04 wait(&h3,&size,&s,MCAPI_INF);

05 msg_send_i(e1,e0,"1",2,N,&h4,&s);
06 wait(&h4,&size,&s,MCAPI_INF);

07 finalize(&s);
\end{alltt}
\end{minipage}
\end{lrbox}

\newsavebox{\boxATOne}
\begin{lrbox}{\boxATOne}
\begin{minipage}[t]{0.65\linewidth}
\begin{alltt}
04 1_0         (1_0 (rcvi rcvC 1 c))
05 (1_1 (1 2)) (1_1 (wait rcvC))

06 1_2         (1_2 (sndi snd3 1 0 0x1))
07 1_3         (1_3 (wait snd3))
\end{alltt}
\end{minipage}
\end{lrbox}

\newsavebox{\boxTTwo}
\begin{lrbox}{\boxTTwo}
\begin{minipage}[t]{0.65\linewidth}
\begin{alltt}
00 initialize(NODE_2,&v,&s);
01 t2 = create_endpoint(PORT_2,&s);
02 t0 = get_endpoint(NODE_0,PORT_0,&s);
03 t1 = get_endpoint(NODE_1,PORT_1,&s);

04 msg_send_i(e2,e0,"4",2,N,&h5,&s);
05 wait(&h5,&size,&s,MCAPI_INF);

06 msg_send_i(e2,e1,"Go",3,N,&h6,&s);
07 wait(&h6,&size,&s,MCAPI_INF);

08 finalize(&s);
\end{alltt}
\end{minipage}
\end{lrbox}

\newsavebox{\boxATTwo}
\begin{lrbox}{\boxATTwo}
\begin{minipage}[t]{0.65\linewidth}
\begin{alltt}
00 2_0        (2_0 (sndi snd1 2 0 0x4))
01 2_1        (2_1 (wait snd1))

02 2_2        (2_2 (sndi snd2 2 1 0x476f00))
03 2_3        (2_3 (wait snd2))
\end{alltt}
\end{minipage}
\end{lrbox}

\newsavebox{\boxMP}
\begin{lrbox}{\boxMP}
\begin{minipage}[c]{0.2\linewidth}
\begin{tabular}[t]{l}
($\mathtt{R_{0,2}}$ $\mathtt{S_{2,4}}$)\\
($\mathtt{R_{0,2}}$ $\mathtt{S_{1,5}}$)\\
\\
($\mathtt{R_{0,5}}$ $\mathtt{S_{2,4}}$)\\
($\mathtt{R_{0,5}}$ $\mathtt{S_{1,5}}$)\\
\\
($\mathtt{R_{1,3}}$ $\mathtt{S_{2,7}}$)\\
\end{tabular}
\end{minipage}
\end{lrbox}


\newsavebox{\boxSMT}
\begin{lrbox}{\boxSMT}
\begin{minipage}[c]{0.4\linewidth}
\begin{alltt}
(HB rcvA_loc wait_rcvA_loc)
(HB wait_rcvA_loc rcvB_loc)
(HB rcvB_loc wait_rcvB_loc)
(HB wait_rcvB_loc assume_loc)
(HB assume_loc assert_loc)
(HB rcvC_loc wait_rcvC_loc)
(HB wait_rcvC_loc snd3_loc)
(HB snd3_loc wait_snd3_loc)
(HB snd1_loc wait_snd1_loc)
(HB wait_snd1_loc snd2_loc)
(HB snd2_loc wait_snd2_loc)

(or (MATCH rcvA snd3)
    (MATCH rcvA snd1))
(or (MATCH rcvB  snd1)
    (MATCH rcvB snd3))
(NE rcvA rcvB)

(MATCH rcvC snd2)

(assert (> b 0))
(assert (not (= a 4)))
\end{alltt}
\end{minipage}
\end{lrbox}
% ---------------------------------------------------------------------
% END Save boxes
% ---------------------------------------------------------------------

\section{Example}

It is a challenge to explain intended behavior in simple scenarios
consisting of a handful of calls when dealing with concurrency. Consider
the MCAPI program in \figref{fig:mcapi} that includes three
tasks that use send (\texttt{mcapi\_msg\_send\_i}) and receive
(\texttt{mcapi\_msg\_recv\_i}) calls to communicate with each other.
Line numbers appear in the first column for each task, and the
declarations of the local variables are omitted for space. Picking up
the scenario just after the endpoints are defined, lines \texttt{02}
and \texttt{05} of task 0 receive two messages on the endpoint
\textit{e0} in variables $A$ and $B$ which are
converted to integer values and stored in variables $a$ and
$b$ on lines \texttt{04} and \texttt{07}; task 1 receives one
message on endpoint \textit{e1} in variable \textit{C} on line
\texttt{03} and then sends the message \textit{``1''} on line \texttt{05} to
\textit{e0}; and finally, task 2 sends messages \textit{``4''} and \textit{``Go''} on
lines \texttt{04} and \texttt{06} to endpoints \textit{e0} and
\textit{e1} respectively. Task 0 has additional code (lines \texttt{08} -
\texttt{09}) to assert properties of the values in $a$ and
$b$. The \texttt{mcapi\_wait} calls block until the associated
send or receive buffer is able to be used. Given the scenario, we
might ask the question: \emph{``What are the possible values of
\texttt{a} and \texttt{b} after the scenario completes?''}





The intuitive trace is presented in the first three columns of \figref{fig:trace}. Note that the fist column contains the task number in \figref{fig:mcapi}. The second column presents the commands identified by the line numbers shown in \figref{fig:mcapi}. Also, we define a shorthand for each command of send(denoted as $\mathtt{S}$), receive(denoted as $\mathtt{R}$), or wait(denoted as $\mathtt{W}$) in the third column for convenience in the presentation. For each command $\mathtt{O_{i,j}(k,\&h)}$, $\mathtt{O \in \{S,R,W\}}$, $\mathtt{i}$ represents the task number, $\mathtt{j}$ represents the command line, $\mathtt{k}$ represents the destination task number, and $\mathtt{h}$ represents the command handler. Note that a specific destination task number can be assigned to each receive, which implies the matched send in the program runtime. To provide the program non-determinism, the destination task number for receive can also be replaced with ``*" in an MCAPI program. From the trace, variable \textit{a} should contain $4$ and variable
\textit{b} should contain $1$ since task 2 must first send message \textit{``4''}
to \textit{e0} before it can send message \textit{``Go''} to \textit{e1};
consequently, task 1 is then able to send message \textit{``1''} to
\textit{e0}. The assume notation asserts the control flow taken by the program execution which in this example, asserts the true branch of the condition on line \texttt{08} of task 0.  At the end of execution the assertion on line \texttt{09}
of task 0 holds and no error is found. Such intuition is a valid
program execution.

To complete a send call, the message can be either copied out into a runtime provided buffer or to an endpoint provided buffer \cite{sarvani:fm09}. We call the first(second) message buffer \textit{infinite-buffer}(\textit{zero-buffer}). It is remarkable that \textit{infinite-buffer} provides more non-deterministic behaviors, because a particular endpoint can receive more messages under the circumstance of \textit{infinite-buffer} while the \textit{zero-buffer} can only allow one message to be received by a specific endpoint at a time. For our example in \figref{fig:mcapi}, if we use \textit{zero-buffer} as the buffer setting, the send call on line \texttt{05} of task 1 can not match with the receive call on line \texttt{02} of task 0. This is because the send call on line \texttt{04} of task 2 must be completed before the send call on line \texttt{06} of task 2 can match with the receive call on line \texttt{03} of task 1. When using \textit{infinite-buffer}, however, we can have another scenario in the fourth and fifth column of \figref{fig:trace} written in the shorthand notation. The variable \textit{a} contains $1$ instead of $4$, since the message \textit{``1''} is sent to \textit{e0} after sending the message \textit{``Go''} to \textit{e1} as it is possible for the send on line \texttt{04} of task 2 to be delayed in transit. The specification indicates that the wait on line \texttt{05} of task 2 returns once the buffer is available. That only means the message is somewhere in the MCAPI runtime; it does not mean the message is delivered. As such, it is possible for the message to be delayed in transit allowing the send from task 1 on line \texttt{05} to arrive at \textit{e0} first and be received in variable \textit{``a''}. Such a scenario is a program execution that results in an assertion failure at line \texttt{09} in \figref{fig:mcapi}. From the discussion above, it is important to consider non-determinism in the MCAPI runtime when testing or debugging an MCAPI program execution. Note that we use \textit{infinite-buffer} for the program execution in the rest of our discussion. The next section presents our method of SMT encoding that follow the same control flow path through an MCAPI program. The encoding can be solved by an SMT solver such as Yices \cite{dutertre:CAV06} and Z3 \cite{demoura:tacas08}, and the non-deterministic behavior of the program can be resolved.

\begin{figure*}
\begin{center}
\setlength{\tabcolsep}{2pt}
\begin{tabular}[t]{c|c|c}
Task 0 & Task 1 & Task 2 \\
\hline
\scalebox{0.5}{\usebox{\boxTZero}}&
\scalebox{0.5}{\usebox{\boxTOne}} &
\scalebox{0.5}{\usebox{\boxTTwo}}\\
%& & \\
%\hline
%\scalebox{0.5}{\usebox{\boxATZero}} &
%\scalebox{0.5}{\usebox{\boxATOne}}  &
%\scalebox{0.5}{\usebox{\boxATTwo}}
\end{tabular}
\end{center}
\caption{An MCAPI concurrent program}
\label{fig:mcapi}
\end{figure*}

\begin{figure*}
\begin{center}
\setlength{\tabcolsep}{1pt}
\scriptsize \begin{tabular}[t]{|c|l|l||c|l|}
\hline
\multicolumn{3}{|c||}{Trace 1} & \multicolumn{2}{|c|}{Trace 2}\\
\hline
Task\  & Command\ & Shorthand\ & Task\ & Command\  \\
\hline
2 & 04 $\mathtt{msg\_send\_i(e2,e0,"4",2,N,\&h5,\&s);}$ & $\mathtt{S_{2,4}(0,\&h5)}$ & 2 & 04 $\mathtt{S_{2,4}(0,\&h5)}$ \\
2 & 05 $\mathtt{wait(\&h5,\&size,\&s,MCAPI\_INF);}$ & $\mathtt{W(\&h5)}$ & 2 & 05 $\mathtt{W(\&h5)}$ \\
0 & 02 $\mathtt{msg\_recv\_i(e0,A,sizeof(A),\&h1,\&s);}$ & $\mathtt{R_{0,2}(2,\&h1)}$ & 2 & 06 $\mathtt{S_{2,6}(1,\&h6)}$ \\
0 & 03 $\mathtt{wait(\&h1,\&size,\&s,MCAPI\_INF);}$ & $\mathtt{W(\&h1)}$ & 2 & 07 $\mathtt{W(\&h6)}$ \\
2 & 06 $\mathtt{msg\_send\_i(e2,e1,"Go",3,N,\&h6,\&s);}$ & $\mathtt{S_{2,6}(1,\&h6)}$ & 1 & 03 $\mathtt{R_{1,3}(2,\&h3)}$ \\
2 & 07 $\mathtt{wait(\&h6,\&size,\&s,MCAPI\_INF);}$ & $\mathtt{W(\&h6)}$ & 1 & 04 $\mathtt{W(\&h3)}$ \\
0 & 04 $\mathtt{a = atoi(A);}$ & & 1 & 05 $\mathtt{S_{1,5}(0,\&h4)}$ \\
1 & 03 $\mathtt{msg\_recv\_i(e1,C,sizeof(C),\&h3,\&s);}$ & $\mathtt{R_{1,3}(2,\&h3)}$ & 1 & 06 $\mathtt{W(\&h4)}$ \\
1 & 04 $\mathtt{wait(\&h3,\&size,\&s,MCAPI\_INF);}$ & $\mathtt{W(\&h3)}$ & 0 & 02 $\mathtt{R_{0,2}(1,\&h1)}$ \\
1 & 05 $\mathtt{msg\_send\_i(e1,e0,''1",2,N,\&h4,\&s);}$ & $\mathtt{S_{1,5}(0,\&h4)}$ & 0 & 03 $\mathtt{W(\&h1)}$ \\
1 & 06 $\mathtt{wait(\&h4,\&size,\&s,MCAPI\_INF);}$ & $\mathtt{W(\&h4)}$ & 0 & 04 $\mathtt{a = atoi(A);}$ \\
0 & 05 $\mathtt{msg\_recv\_i(e0,B,sizeof(B),\&h2,\&s);}$ & $\mathtt{R_{0,5}(1,\&h2)}$ & 0 & 05 $\mathtt{R_{0,5}(2,\&h2)}$\\
0 & 06 $\mathtt{wait(\&h2,\&size,\&s,MCAPI\_INF);}$ & $\mathtt{W(\&h2)}$ & 0 & 06 $\mathtt{W(\&h2)}$ \\
0 & 07 $\mathtt{b = atoi(B);}$ & & 0 & 07 $\mathtt{b = atoi(B);}$ \\
0 & 08 $\mathtt{assume (b > 0);}$ & & 0 & 08 $\mathtt{assume (b > 0);}$ \\
0 & 09 $\mathtt{assert(a == 4);}$ & & 0 & 09 $\mathtt{assert(a == 4);}$ \\
\hline
\end{tabular}
\end{center}
\caption{Two execution traces of the MCAPI program in \figref{fig:mcapi}}
\label{fig:trace}
\end{figure*}

%The novelty of the SMT encoding in this paper is its use of match pairs rather than the state-based or order-based encoding of prior work~\cite{elwakil:padtad10,elwakil:atva10}. A match pair is the coupling of a receive to a particular send. \figref{fig:smt}(a) is the set of possible match pairs for the CTP in the bottom of \figref{fig:mcapi} for our running example. The set admits, for example, that \texttt{rcvA} can be matched with either \texttt{snd1} or \texttt{snd2}. The SMT encoding in this paper asks the SMT solver to resolve the match pairs for the system.


