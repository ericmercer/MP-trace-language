\section{Experiments and Results}
%In Section 4, we know that a well defined SMT problem can encode all possible execution traces for a CTP given a precise set of match pair. A precise set of match pair contains all possible match pairs that can exist in the real execution, and all match pairs that can not exist in the execution are not included. In other words, every hidden error can be found if it exists in some trace.
We have implemented the tracking and analysis algorithms in the setting of MCAPI reference implementation. Our tool is capable of handling C programs for MCAPI semantics using the Linux \textit{PThreads} library. In particular, the tool generates an execution trace under the environment of MCAPI reference implementation. The match set generation algorithm presented in Section 4 then builds an over-approximated match set. The tool then builds an SMT encoding based on the generated execution trace and match set. We use the \textit{Yices} SMT solver \cite{dutertre:CAV06} to check the satisfiability of the generated SMT encoding.

To evaluate the reliability and efficiency of our system, we compare to \cite{elwakil:padtad10} even though it misses valid MCAPI runtime behavior because it is the only other encoding for MCAPI programs and it suffices to illustrate the efficiency of our encoding. Two sets of benchmarks are used in the comparison. The first set consists of four ``toy" examples, including the example in \figref{fig:mcapi}. Those examples contain small amount of operations and simple message communications. Since the communications of those examples are commonly used in MCAPI applications, it is feasible to test if the SMT problem of an MCAPI program is able to capture the rumtime behavior with program violation by comparing the set of benchmarks. Also, because the runtime differences for both encodings are very small, we use the number of clauses from each encoding for the same example to compare the efficiency. The other set of benchmarks consists of five large programs. One of them, we call ``leader election", basically elects a leader from several candidates by message communications. The other four programs, are all extensions to the original program in \figref{fig:mcapi}. In particular, extra iterations are added to the original program so that more message passing will occupy and more properties will be checked. In all benchmarks, the correctness
properties are numerical assertions over variables. The experiments were conducted on a PC with 1.6 GHz Intel Quad Core processor and 8GB memory running Ubuntu 14.

\begin{table}
\begin{center}
\scriptsize
\begin{tabular}{|c|c|c|c|c|c|}
    \hline
     &Program Order&Matches&Assume$\&$Assert&Extra Clauses\\
    \hline
    Our Encoding & 11 & 4 & 2 & 0\\
    Encoding in \cite{elwakil:padtad10} & 22 & 13 & 3 & 8\\
    \hline
\end{tabular}
\end{center}
\caption{Comparison of two encodings for the MCAPI program in \figref{fig:mcapi}.}
\label{table:program}
\end{table}
As for the first set of benchmarks, \tableref{table:program} shows the comparison of our encoding and the encoding in \cite{elwakil:padtad10} on the example in \figref{fig:mcapi}.  Basically, we encode 17 clauses for modeling the program in \figref{fig:mcapi}, omitting the definition of variables at the beginning of the encoding. Instead, the encoding in \cite{elwakil:padtad10} has 47 clauses for the same program, omitting the definitions as well. The number of clauses that constrain program order, match pairs, assume/asserts, and any other extra uncategorized clauses are also shown in \tableref{table:program}. Program order comprises the bulk of the encoding. The extra clauses in \cite{elwakil:padtad10} come from auxiliary variables in the encoding.

\begin{table}
\begin{center}
\scriptsize
\begin{tabular}{|l|c||c|c|c|c|}
		\hline
         \multicolumn{2}{|c||}{Test Programs} & \multicolumn{2}{|c|}{Our Encoding} & \multicolumn{2}{|c|}{Encoding in \cite{elwakil:padtad10}}\\ \hline
         Name & \# Messages & Property & \# Clauses & Property & \# Clauses \\ \hline
         EP in \figref{fig:mcapi} & 3 & sat & 17 & unsat & 47 \\
         \textit{Small1} & 2 & unsat & 8 & unsat & 33 \\
         \textit{Small2} & 1 & unsat  & 4 & unsat & 18 \\
         \textit{Small3} & 3 & sat & 11 & unsat & 44 \\
         \hline
		\end{tabular}
\end{center}
\caption{Comparison of two encodings for four ``toy" MCAPI programs with property and clause number.}
\label{table:comparison}
\end{table}

Other than the program in \figref{fig:mcapi}, we manually generate three programs and provide the experimental results in \tableref{table:comparison}. \textit{Small1} is a program with two tasks, where two sends are in the first task, and two receives are in the second task. From our previous discussion, the sends in \textit{Small1} should be received in a FIFO way since the sends own identical source and destination endpoints. \textit{Small2} is a program with only one task, where one send and one receive are contained. The send can be received by the only task. \textit{Small3} is a program with three tasks, where three sends are in the first task, two receives are in the second task, and one receive is in the third task. From our discussion of the matching criteria in Section 4, the assert where the first send in the first task is received by the second receive in the second task in \textit{Small3} should fail. \tableref{table:comparison} shows the properties of our encodings and the encodings in \cite{elwakil:padtad10} on each benchmark. The properties of our encodings shown in \tableref{table:comparison} are checked with correct answers by the SMT solver. In particular, our encodings return ``sat" for the example in \figref{fig:mcapi} and \textit{Small3} since violations are detected for both scenarios. Also, our encodings return ``unsat" for \textit{Small1} and \textit{Small2}, meaning there are no errors in program rumtimes. From the results, it is also shown that the encoding in \cite{elwakil:padtad10} does not always encode the correct program behavior. In addition to the correctness of properties, the number of clauses shown in \tableref{table:comparison} follows the performance of the SMT solver with fewer clauses leading to better runtime. \tableref{table:comparison} shows that our encoding generates  1/5 -- 1/3  the clauses of that of the encoding in \cite{elwakil:padtad10}. We believe these reductions will generalize to any given program trace and match pair set.

\begin{table}
\begin{center}
\scriptsize
\begin{tabular}{|l|c||c|c|c|c|}
		\hline
         \multicolumn{2}{|c||}{Test Programs} & \multicolumn{2}{|c|}{Our Encoding} & \multicolumn{2}{|c|}{Encoding in \cite{elwakil:padtad10}}\\ \hline
         Name & \# Messages & Time(ms) & Memory(mb) & Time(ms) & Memory(mb) \\ \hline
         \textit{LeaderElect} & 30 & -- & -- &-- &-- \\
         \textit{5iterations} & 15 & 72 &  18.5195 & 392 & 37.2188 \\
         \textit{6iterations} & 18 & 72  & 18.918 & 636 & 48.7031 \\
         \textit{7iterations} & 21 & 80 & 19.375 & 940 & 62.7188 \\
         \textit{8iterations} & 24 & -- &-- &-- &-- \\
         \hline
		\end{tabular}
\end{center}
\caption{Comparison of two encodings for five ``large" MCAPI programs with runtime and used memory.}
\label{table:comparison1}
\end{table}

As for the second set of benchmarks, we compare the runtime and memory usage for each program. In this series of experiments, the encodings in \cite{elwakil:padtad10} are not capable to resolve all the non-deterministic behaviors without \textit{infinite-buffer} semantics. As such, we revise our encodings for the same scenarios in \textit{zero-buffer} setting in order to obtain the same behavior of the encodings in \cite{elwakil:padtad10}. \tableref{table:comparison1} shows the experimental results for the ``large" MCAPI programs. The results shown in \tableref{table:comparison1} are observable such that the runtimes and the memory usage of our encodings are smaller than those of the encodings in \cite{elwakil:padtad10} for all programs in the experiments. In average, our encodings run eight times faster than the encodings in \cite{elwakil:padtad10} and use two times less memory than the encodings in \cite{elwakil:padtad10}.

By comparing to the encoding in \cite{elwakil:padtad10} on two series of experiments shown above, our encoding is demonstrated that it can correctly encode the non-determinism of an MCAPI program, and can be executed efficiently for detecting errors in MCAPI application.

